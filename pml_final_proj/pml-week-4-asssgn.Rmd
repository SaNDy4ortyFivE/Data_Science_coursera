---
title: "PML Week 4 assignment"
author: "Karan Sandam"
date: "23/08/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

The aim of this project is to predict the 'classe' variable in the dataset and test the model on provided test set. The preprocessing stage involves removing columns with NA and having near zero variance between them. The provided training set is split into two parts viz. train1 and train2 for traning and testing respectively. For final prediction provided test dataset is used.  
Two models have been fitted 1.SVM 2.Random Forest(ranger). Out of these random forest gives better accuracy on test data of training set and hence will be used for predictions in final test set.  

### Setting up the Environment

```{r initial, cache=TRUE}
library(caret)
packageVersion("caret")
library(e1071)
packageVersion("e1071")
library(dplyr)
packageVersion("dplyr")
## For taking advantage of multicore CPU
library(doParallel)
packageVersion("doParallel")
```

### Setting up multicore environment

By default R uses single core for a rsession. In order to take advantage of remaining cores we will use the doParallel package and allocate 50%(no. of cores/2) of cpu to a rsession.

```{r setting up multicore, cache=TRUE}
## Only physical cores
cores = detectCores(logical = FALSE)
cr <- makePSOCKcluster(as.integer(cores/2))
registerDoParallel(cr)
```
Now we can utilize 50% of our cpu to train the models.

### Loading the data

```{r loading data, cache=TRUE}
training <- read.csv("pml-training.csv")
dim(training)
testing <- read.csv("pml-testing.csv")
dim(testing)
```

### Data Preprocessing

We will preprocess the training data and then extract only those columns from testing data which are left after preprocessing.  

```{r data preprocessing,cache=TRUE}
col_names <- names(training)
na_cols <- ""           ##columns which are empty
for(n in col_names){
        if(sum(is.na(training[,n]))>10){
                na_cols<-append(na_cols,n)
        }
}
head(na_cols)
## removing 1st element since it was dummy
na_cols <- na_cols[2:length(na_cols)]
head(na_cols)
```

Selecting only those columns from training set which are not there in na_cols(columns in na_cols have NA's hence need to be excluded)

```{r removing NA cols, cache=TRUE}
training <- select(training,!all_of(na_cols))
dim(training)
```

Now lets take a look at our training set 

```{r quick peek, cache=TRUE}
names(training)
head(training[1:10,1:10])
```

It can be seen that initial 7 columns are not needed for building the model. Hence dropping them

```{r drop not need columns}
training <- training[,8:93]
dim(training)
```

So major part of pre processing is done. Now lets remove columns with near zero variance.

```{r remove near zero v, cache=TRUE}
nzv <- nearZeroVar(training)
training <- training[,-nzv]
dim(training)
```

Now we are left with 52 variables(excl. output) to feed into our model.  

Keeping only those columns in test set which are present in training

```{r remove from test, cache=TRUE}
col_names <- names(training)
##removing the classe because its the output in test set which is to be predicted
col_names <- col_names[1:length(col_names)-1]
testing <- select(testing,all_of(col_names))
dim(testing)
```

The dimensions of our training and testing set are now matching.(excluding output variable)

### Partitioning the dataset
```{r partition the dataset, cache=TRUE}
set.seed(45)
intrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
train1 <- training[intrain,]
train2 <- training[-intrain,]
```

## Building the SVM
```{r building svm, cache=TRUE}
set.seed(46)
library(e1071)
model_svm <- svm(classe ~.,data = train1, type="C")
```

#### Prediction by SVM
```{r prediction by SVM, cache=TRUE}
library(e1071)          ##predict function from this package
pred_svm <- predict(model_svm, train2)
conf_svm<-confusionMatrix(train2$classe, pred_svm)
conf_svm
plot(conf_svm$table, col=conf_svm$byClass,
     main = paste ("SVM Accuracy=", round (conf_svm$overall['Accuracy'],3)))
```

__Model Accuracy:`r round(conf_svm$overall['Accuracy'],3)`__ 

## Building a RandomForest(ranger)  

_Ranger is a fast implementation of random forests (Breiman 2001) or recursive partitioning, particularly suited for high dimensional data._  

```{r traincontrol, cache=TRUE}
fitControl <- trainControl(
        method = "oob", ##for 'oob(out of bag) score for random forest'
        number = 3,)
```

Lets fit the model now with train function

```{r rf, cache=TRUE}
set.seed(47)
model_rf <- train(as.factor(classe) ~ ., data = train1, 
                 method = "ranger", 
                 trControl = fitControl,
                 verbose = TRUE)
model_rf
```

### Prediction by RandomForest(ranger)

```{r prediction by rf,cache=TRUE}
library(caret)          ##predict function from this package
pred_rf <- predict(model_rf,train2)
conf_rf<-confusionMatrix(train2$classe, pred_rf)
conf_rf
plot(conf_rf$table, col=conf_rf$byClass,
     main = paste ("RandomForest(ranger) Accuracy=", round (conf_rf$overall['Accuracy'],3)))
```

````{r versus plots}
library(ggplot2)
qplot(pred_rf,pred_svm,colour=classe, data=train2)
```

The differences in predictions can be clearly seen.  

__Model Accuracy:`r round(conf_rf$overall['Accuracy'],3)`__  

Out of both the models RandomForest(ranger) has greater out of sample accuracy. Hence will be used for final predictions.  

## Final Prediction  

Test data is already preprocessed, so we can directly predict it.

```{r final prediction, cache=TRUE}
library(caret)
fin_pred <- predict(model_rf, testing)
fin_pred
```


```{r}
library(doParallel)
##stopping the multi-core environment
stopImplicitCluster()
```
## References  
[Caret Package](https://topepo.github.io/caret/)  
[Caret Tutorial](http://www.rebeccabarter.com/blog/2017-11-17-caret_tutorial/)
